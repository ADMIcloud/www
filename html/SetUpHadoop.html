
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Set Up Hadoop &mdash; ADMICloud  documentation</title>
    
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="ADMICloud  documentation" href="index.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head>
  <body role="document">

    <p style="text-align:center;"><img src="_static/images/cover.jpg"></p>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="set-up-hadoop">
<h1>Set Up Hadoop<a class="headerlink" href="#set-up-hadoop" title="Permalink to this headline">¶</a></h1>
<div class="section" id="hadoop">
<h2>Hadoop<a class="headerlink" href="#hadoop" title="Permalink to this headline">¶</a></h2>
<div class="figure">
<a class="reference internal image-reference" href="http://hadoop.apache.org/images/hadoop-logo.jpg"><img alt="Hadoop" src="http://hadoop.apache.org/images/hadoop-logo.jpg" style="width: 400px;" /></a>
</div>
<p>Hadoop is an open source framework for distributed storage and processing of large datasets on a commodity cluster. Hadoop utilizes the Hadoop Distributed File System (HDFS) for data storage and the MapReduce model for computational processing. Hadoop 2.0 also includes the YARN resource management platform which manages multiple nodes within the cluster and is responsible for task scheduling.</p>
<p>This section describes how to set up Hadoop on one instance.</p>
</div>
<div class="section" id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Java</p>
<p>Download Oracle JDK 8 from <a class="reference external" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a>
Extract the archive using the following steps:</p>
</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nb">cd</span>
mkdir software
<span class="nb">cd</span> software
wget --no-cookies --no-check-certificate --header <span class="s2">&quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot;</span> <span class="s2">&quot;http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.tar.gz&quot;</span>
tar xzf jdk-8u91-linux-x64.tar.gz
</pre></div>
</div>
<p>Set the following environment variables (you can set the variables in the .bashrc file). You can use the following command to open and edit the .bashrc file. We also need to install vim editor to edit the files.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>sudo apt-get install vim
vim ~/.bashrc
</pre></div>
</div>
<p>Add the the following lines to the end of the code:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nv">JAVA_HOME</span><span class="o">=</span>~/software/jdk1.8.0_91
<span class="nv">PATH</span><span class="o">=</span><span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>
<span class="nb">export</span> JAVA_HOME PATH
</pre></div>
</div>
<p>Now run the following command in order to make sure the changes are applied. You should see an output similar to the one given below after running the code.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nb">source</span> ~/.bashrc
java -version
</pre></div>
</div>
<div class="highlight-bash"><div class="highlight"><pre><span></span>java version <span class="s2">&quot;1.8.0_66&quot;</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_66-b17<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.66-b17, mixed mode<span class="o">)</span>
</pre></div>
</div>
<ol class="arabic" start="2">
<li><p class="first">SSH and Rsync</p>
<p>Install SSH and Rsync are not already installed in the environment. Use these commands to add them.</p>
</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>sudo apt-get install ssh
sudo apt-get install rsync
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>Download and extract the latest Hadoop binary into your machine. These are available at <a class="reference external" href="http://hadoop.apache.org/releases.html">http://hadoop.apache.org/releases.html</a>. The following commands will download and extract Hadoop version 2.7.2.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nb">cd</span> ~/software
wget http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz
tar -xzvf hadoop-2.7.2.tar.gz
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Make sure everything was done properly, then execute the following command from the Hadoop folder that we just extracted</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>./bin/hadoop
</pre></div>
</div>
</div>
<div class="section" id="set-up-passphrase-less-ssh">
<h2>Set up passphrase-less ssh<a class="headerlink" href="#set-up-passphrase-less-ssh" title="Permalink to this headline">¶</a></h2>
<p>First, check your code with the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ ssh localhost
</pre></div>
</div>
<p>If you cannot ssh to the localhost without a passphrase, use the following commands to set up passphrase-less ssh:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> ~/.ssh
$ ssh-keygen -t rsa
<span class="o">(</span>hit enter to all the options<span class="o">)</span>
$ cat id_rsa.pub &gt;&gt; authorized_keys
</pre></div>
</div>
</div>
<div class="section" id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<p>Modify the following files, replacing $HADOOP_HOME with your own Hadoop home path.</p>
<p>In $HADOOP_HOME/etc/hadoop/hadoop-env.sh, replace ${JAVA_HOME} with your own Java home path. If it is ~/software/jdk1.8.0_91, then add the following:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="c1"># The java implementation to use.</span>
<span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>~/software/jdk1.8.0_91#The java implementation to use.
</pre></div>
</div>
<p>$HADOOP_HOME/etc/hadoop/core-site.xml</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://localhost:9010<span class="nt">&lt;/value&gt;</span>
     <span class="nt">&lt;/property&gt;</span>

    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>$HADOOP_HOME/tmp<span class="nt">&lt;/value&gt;</span>
        <span class="nt">&lt;description&gt;</span>A base for other temporary directories.<span class="nt">&lt;/description&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
<p>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
<p>$HADOOP_HOME/etc/hadoop/mapred-site.xml</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
<p>$HADOOP_HOME/etc/hadoop/yarn-site.xml</p>
<div class="highlight-xml"><div class="highlight"><pre><span></span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>localhost<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="start-daemons">
<h2>Start Daemons<a class="headerlink" href="#start-daemons" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Format the file system next.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs namenode -format
</pre></div>
</div>
<p>If you can see information like this, the format process should be successful.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>xx/xx/xx xx:xx:xx INFO util.ExitUtil: Exiting with status 0
xx/xx/xx xx:xx:xx INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at xxx.xxx.xxx.xxx
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li>Launch NameNode daemon and DataNode daemon</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/sbin/start-dfs.sh
</pre></div>
</div>
<p>The log is in the $HADOOP_LOG_DIR directory (defaults: $HADOOP_HOME/logs).</p>
<ol class="arabic simple" start="3">
<li>Check if the daemons started successfully.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ jps
xxxxx NameNode
xxxxx SecondaryNameNode
xxxxx DataNode
xxxxx Jps
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>Browse the web interface for the NameNode. By default this is at <a class="reference external" href="http://localhost:50070">http://localhost:50070</a></li>
<li>Start ResourceManager daemon and NodeManager Daemon</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/sbin/start-yarn.sh
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li>Verify the daemons started sucessfully:</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ jps
xxxxx NameNode
xxxxx SecondaryNameNode
xxxxx DataNode
xxxxx NodeManager
xxxxx Jps
xxxxx ResourceManager
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li>Browse the web interface for the ResourceManager. By default this should be <a class="reference external" href="http://localhost:8088">http://localhost:8088</a></li>
</ol>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Make the Hadoop Distributed File System (HDFS) directories.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs dfs -mkdir -p .
$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs dfs -mkdir input
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li>Copy the input files into HDFS. In this example, we use files in $HADOOP_HOME/etc/hadoop/ directory as input files.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs dfs -put <span class="nv">$HADOOP_HOME</span>/etc/hadoop/* input
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li>Run the &#8220;grep&#8221; example provided.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output <span class="s1">&#39;hadoop&#39;</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li>View the output files on HDFS.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs dfs -cat output/*
</pre></div>
</div>
<p>Or copy the output files to the local filesystem.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/bin/hdfs dfs -get output output
$ cat output/*
</pre></div>
</div>
</div>
<div class="section" id="stop-daemons">
<h2>Stop daemons.<a class="headerlink" href="#stop-daemons" title="Permalink to this headline">¶</a></h2>
<p>If you are done, you can stop all daemons by using this code:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ <span class="nv">$HADOOP_HOME</span>/sbin/stop-dfs.sh
$ <span class="nv">$HADOOP_HOME</span>/sbin/stop-yarn.sh
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><ul class="globaltoc"
><ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Cloud Computing Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="members.html">Members</a></li>
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
</ul>

</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">ADMICloud  documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, DSC.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.1.
    </div>
  </body>
</html>